{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed562961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if a GPU is available\n",
    "is_available = torch.cuda.is_available()\n",
    "print(f\"GPU available: {is_available}\")\n",
    "\n",
    "if is_available:\n",
    "    # Get the name of the GPU\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    # Get the number of GPUs\n",
    "    print(f\"Device count: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "bf146ebc",
   "metadata": {},
   "outputs": [],
   "source": "# Reddit Business Ideas Finder\n\nThis notebook contains code to search Reddit for business ideas based on a given keyword. It will:\n1. Search for relevant subreddits related to the keyword\n2. Find top posts in those subreddits\n3. Analyze discussions to identify potential business opportunities\n4. Return structured business ideas with supporting data"
  },
  {
   "cell_type": "code",
   "id": "tdsh70kioj",
   "source": "# Install required packages\n# Uncomment the line below to install dependencies\n# !pip install praw anthropic python-dotenv\n\nimport praw\nimport os\nfrom typing import List, Dict, Any\nfrom datetime import datetime\nfrom dotenv import load_dotenv\nimport json\n\n# Load environment variables\nload_dotenv()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "17b8im8hzg5",
   "source": "def search_relevant_subreddits(reddit: praw.Reddit, keyword: str, limit: int = 10) -> List[Dict[str, Any]]:\n    \"\"\"\n    Search for subreddits related to the given keyword.\n    \n    Args:\n        reddit: Authenticated Reddit client instance\n        keyword: The keyword to search for\n        limit: Maximum number of subreddits to return (default: 10)\n    \n    Returns:\n        List of dictionaries containing subreddit information:\n        - name: Subreddit name\n        - subscribers: Number of subscribers\n        - description: Subreddit description\n        - url: URL to the subreddit\n    \"\"\"\n    subreddits = []\n    \n    try:\n        for subreddit in reddit.subreddits.search(keyword, limit=limit):\n            subreddits.append({\n                'name': subreddit.display_name,\n                'subscribers': subreddit.subscribers,\n                'description': subreddit.public_description,\n                'url': f\"https://reddit.com/r/{subreddit.display_name}\"\n            })\n    except Exception as e:\n        print(f\"Error searching subreddits: {e}\")\n    \n    return sorted(subreddits, key=lambda x: x['subscribers'], reverse=True)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5i1pjlf2t2m",
   "source": "def get_top_comments(reddit: praw.Reddit, post_url: str, limit: int = 10) -> List[Dict[str, Any]]:\n    \"\"\"\n    Get top comments from a Reddit post.\n    \n    Args:\n        reddit: Authenticated Reddit client instance\n        post_url: URL or permalink of the post\n        limit: Maximum number of top comments to retrieve (default: 10)\n    \n    Returns:\n        List of dictionaries containing comment information:\n        - body: Comment text\n        - score: Comment score\n        - author: Comment author username\n    \"\"\"\n    comments = []\n    \n    try:\n        submission = reddit.submission(url=post_url)\n        submission.comments.replace_more(limit=0)  # Remove \"load more comments\" objects\n        \n        for comment in submission.comments[:limit]:\n            if hasattr(comment, 'body'):\n                comments.append({\n                    'body': comment.body[:300] if comment.body else '',  # Limit text length\n                    'score': comment.score,\n                    'author': str(comment.author) if comment.author else '[deleted]'\n                })\n    except Exception as e:\n        print(f\"Error fetching comments: {e}\")\n    \n    return sorted(comments, key=lambda x: x['score'], reverse=True)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ihs1u0b97oo",
   "source": "def find_business_ideas_from_reddit(keyword: str, \n                                     num_subreddits: int = 5,\n                                     posts_per_subreddit: int = 10,\n                                     time_filter: str = 'month') -> Dict[str, Any]:\n    \"\"\"\n    Main function to find business ideas from Reddit based on a keyword.\n    \n    This function orchestrates the entire process:\n    1. Searches for relevant subreddits\n    2. Finds top posts in those subreddits\n    3. Analyzes discussions to extract business opportunities\n    4. Returns structured business ideas with supporting data\n    \n    Args:\n        keyword: The keyword/niche to search for\n        num_subreddits: Number of subreddits to search (default: 5)\n        posts_per_subreddit: Number of posts to fetch per subreddit (default: 10)\n        time_filter: Time filter for posts ('month', 'week', 'year', etc.)\n    \n    Returns:\n        Dictionary containing:\n        - keyword: The search keyword\n        - subreddits: List of relevant subreddits found\n        - posts: All posts collected\n        - business_ideas: List of identified business opportunities\n        - metadata: Search metadata (timestamp, counts, etc.)\n    \"\"\"\n    print(f\"ðŸ” Searching Reddit for business ideas related to: '{keyword}'\")\n    \n    # Initialize Reddit client\n    reddit = initialize_reddit_client()\n    \n    # Step 1: Find relevant subreddits\n    print(f\"\\nðŸ“ Finding relevant subreddits...\")\n    subreddits = search_relevant_subreddits(reddit, keyword, limit=num_subreddits)\n    print(f\"Found {len(subreddits)} subreddits\")\n    \n    # Step 2: Search posts in each subreddit\n    print(f\"\\nðŸ“ Searching posts in subreddits...\")\n    all_posts = []\n    for subreddit in subreddits[:num_subreddits]:\n        print(f\"  - Searching r/{subreddit['name']}...\")\n        posts = search_posts_in_subreddit(\n            reddit, \n            subreddit['name'], \n            keyword, \n            limit=posts_per_subreddit,\n            time_filter=time_filter\n        )\n        all_posts.extend(posts)\n    \n    print(f\"Found {len(all_posts)} total posts\")\n    \n    # Step 3: Analyze for business ideas\n    print(f\"\\nðŸ¤– Analyzing posts with AI to extract business ideas...\")\n    business_ideas = analyze_for_business_ideas(all_posts, keyword)\n    print(f\"Identified {len(business_ideas)} business ideas\")\n    \n    # Compile results\n    results = {\n        'keyword': keyword,\n        'search_metadata': {\n            'timestamp': datetime.now().isoformat(),\n            'num_subreddits_searched': len(subreddits),\n            'num_posts_analyzed': len(all_posts),\n            'time_filter': time_filter\n        },\n        'subreddits': subreddits,\n        'top_posts': sorted(all_posts, key=lambda x: x['score'], reverse=True)[:20],\n        'business_ideas': business_ideas\n    }\n    \n    return results",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "dkncenh4zj4",
   "source": "def save_results_to_file(results: Dict[str, Any], filename: str = None) -> str:\n    \"\"\"\n    Save the business ideas results to a JSON file.\n    \n    Args:\n        results: Dictionary returned from find_business_ideas_from_reddit()\n        filename: Optional custom filename. If not provided, generates one from keyword and timestamp\n    \n    Returns:\n        Path to the saved file\n    \"\"\"\n    if filename is None:\n        keyword_clean = results['keyword'].replace(' ', '_').lower()\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        filename = f\"reddit_business_ideas_{keyword_clean}_{timestamp}.json\"\n    \n    with open(filename, 'w', encoding='utf-8') as f:\n        json.dump(results, f, indent=2, ensure_ascii=False)\n    \n    print(f\"âœ… Results saved to: {filename}\")\n    return filename",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "3do53m2nc7i",
   "source": "# Alternative: Quick test with any keyword\n# Replace 'your_keyword_here' with any topic you want to explore\n\n# keyword = input(\"Enter a keyword to search for business ideas: \")\n# results = find_business_ideas_from_reddit(keyword)\n# display_results(results)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4g2w837cbjq",
   "source": "## Output Structure\n\nThe `find_business_ideas_from_reddit()` function returns a dictionary with the following structure:\n\n```json\n{\n  \"keyword\": \"your search keyword\",\n  \"search_metadata\": {\n    \"timestamp\": \"2026-01-13T...\",\n    \"num_subreddits_searched\": 5,\n    \"num_posts_analyzed\": 50,\n    \"time_filter\": \"month\"\n  },\n  \"subreddits\": [\n    {\n      \"name\": \"subreddit_name\",\n      \"subscribers\": 100000,\n      \"description\": \"Subreddit description\",\n      \"url\": \"https://reddit.com/r/subreddit_name\"\n    }\n  ],\n  \"top_posts\": [\n    {\n      \"title\": \"Post title\",\n      \"score\": 1500,\n      \"num_comments\": 200,\n      \"url\": \"https://...\",\n      \"permalink\": \"https://reddit.com/r/.../comments/...\",\n      \"created_utc\": \"2026-01-13T...\",\n      \"selftext\": \"Post content...\",\n      \"author\": \"username\"\n    }\n  ],\n  \"business_ideas\": [\n    {\n      \"idea_title\": \"Business Idea Title\",\n      \"description\": \"Detailed description...\",\n      \"target_audience\": \"Who this serves...\",\n      \"pain_point\": \"Problem it solves...\",\n      \"evidence\": \"Quotes from Reddit...\",\n      \"potential\": \"High/Medium/Low\",\n      \"keywords\": [\"tag1\", \"tag2\"]\n    }\n  ]\n}\n```\n\n### Tips for Best Results:\n\n1. **Choose specific keywords**: Instead of broad terms like \"business\", use specific niches like \"AI content creation\" or \"eco-friendly packaging\"\n2. **Adjust time filters**: Use 'week' for trending topics, 'year' or 'all' for established niches\n3. **Increase post limits**: More posts = better analysis, but slower execution\n4. **Review subreddits**: The most active subreddits often have the best discussions\n5. **Cross-reference ideas**: Look for patterns across multiple posts and subreddits",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "aez0zi9h3uf",
   "source": "# Example: Search for business ideas related to \"sustainable fashion\"\n# Uncomment and run the code below after setting up your API credentials\n\n# keyword = \"sustainable fashion\"\n# results = find_business_ideas_from_reddit(\n#     keyword=keyword,\n#     num_subreddits=5,\n#     posts_per_subreddit=15,\n#     time_filter='month'\n# )\n# \n# # Display the results in a formatted way\n# display_results(results)\n# \n# # Save results to JSON file\n# save_results_to_file(results)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2q1irfrlzlq",
   "source": "## Usage Example\n\nTo use this Reddit Business Ideas Finder, you need to set up the following environment variables:\n\n### Required Environment Variables:\n\nCreate a `.env` file in the same directory with:\n\n```\nREDDIT_CLIENT_ID=your_reddit_client_id\nREDDIT_CLIENT_SECRET=your_reddit_client_secret\nREDDIT_USER_AGENT=YourAppName/1.0\nANTHROPIC_API_KEY=your_anthropic_api_key\n```\n\n### Getting Reddit API Credentials:\n\n1. Go to https://www.reddit.com/prefs/apps\n2. Click \"Create App\" or \"Create Another App\"\n3. Select \"script\" as the app type\n4. Fill in the name and description\n5. Copy the client ID (under the app name) and client secret\n\n### Getting Anthropic API Key:\n\n1. Sign up at https://console.anthropic.com\n2. Navigate to API Keys\n3. Create a new API key\n\n### Example Usage:\n\n```python\n# Search for business ideas related to a keyword\nresults = find_business_ideas_from_reddit(\n    keyword=\"AI automation\",\n    num_subreddits=5,\n    posts_per_subreddit=15,\n    time_filter='month'\n)\n\n# Display the results\ndisplay_results(results)\n\n# Save to file\nsave_results_to_file(results)\n```",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "cyo1q7z3ti5",
   "source": "def display_results(results: Dict[str, Any]) -> None:\n    \"\"\"\n    Display the business ideas search results in a readable format.\n    \n    Args:\n        results: Dictionary returned from find_business_ideas_from_reddit()\n    \"\"\"\n    print(\"=\" * 80)\n    print(f\"REDDIT BUSINESS IDEAS ANALYSIS: {results['keyword'].upper()}\")\n    print(\"=\" * 80)\n    \n    # Display metadata\n    metadata = results['search_metadata']\n    print(f\"\\nðŸ“Š Search Summary:\")\n    print(f\"   Timestamp: {metadata['timestamp']}\")\n    print(f\"   Subreddits searched: {metadata['num_subreddits_searched']}\")\n    print(f\"   Posts analyzed: {metadata['num_posts_analyzed']}\")\n    print(f\"   Time filter: {metadata['time_filter']}\")\n    \n    # Display subreddits\n    print(f\"\\nðŸ“ Relevant Subreddits:\")\n    for i, sub in enumerate(results['subreddits'][:5], 1):\n        print(f\"   {i}. r/{sub['name']} ({sub['subscribers']:,} subscribers)\")\n        print(f\"      {sub['description'][:100]}...\")\n    \n    # Display business ideas\n    print(f\"\\nðŸ’¡ Business Ideas ({len(results['business_ideas'])} found):\")\n    print(\"=\" * 80)\n    \n    for i, idea in enumerate(results['business_ideas'], 1):\n        print(f\"\\n{i}. {idea.get('idea_title', idea.get('title', 'Untitled Idea'))}\")\n        print(f\"   {'-' * 70}\")\n        print(f\"   Description: {idea.get('description', 'N/A')}\")\n        print(f\"   Target Audience: {idea.get('target_audience', 'N/A')}\")\n        print(f\"   Pain Point: {idea.get('pain_point', 'N/A')}\")\n        print(f\"   Market Potential: {idea.get('potential', idea.get('market_potential', 'N/A'))}\")\n        if 'evidence' in idea:\n            print(f\"   Evidence: {idea['evidence'][:150]}...\")\n        if 'keywords' in idea:\n            keywords = idea['keywords'] if isinstance(idea['keywords'], str) else ', '.join(idea['keywords'])\n            print(f\"   Keywords: {keywords}\")\n    \n    print(\"\\n\" + \"=\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ytpjpayhlom",
   "source": "def analyze_for_business_ideas(posts_data: List[Dict[str, Any]], keyword: str) -> List[Dict[str, Any]]:\n    \"\"\"\n    Analyze Reddit posts and comments to extract potential business ideas.\n    \n    This function uses Claude AI to analyze discussions and identify business opportunities,\n    pain points, feature requests, and market gaps related to the keyword.\n    \n    Args:\n        posts_data: List of post dictionaries with titles, content, and comments\n        keyword: The keyword/niche being analyzed\n    \n    Returns:\n        List of dictionaries containing business ideas:\n        - idea_title: Brief title of the business idea\n        - description: Detailed description of the opportunity\n        - target_audience: Who would benefit from this\n        - pain_point: What problem it solves\n        - evidence: Supporting quotes/data from Reddit\n        - potential: Estimated market potential (High/Medium/Low)\n        - keywords: Related keywords and tags\n    \"\"\"\n    from anthropic import Anthropic\n    \n    # Initialize Anthropic client\n    client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))\n    \n    # Prepare context from Reddit posts\n    context = f\"Keyword: {keyword}\\n\\n\"\n    for i, post in enumerate(posts_data[:10], 1):  # Limit to top 10 posts\n        context += f\"Post {i}:\\n\"\n        context += f\"Title: {post['title']}\\n\"\n        context += f\"Score: {post['score']} | Comments: {post['num_comments']}\\n\"\n        if post['selftext']:\n            context += f\"Content: {post['selftext'][:300]}...\\n\"\n        context += \"\\n\"\n    \n    # Create prompt for Claude\n    prompt = f\"\"\"Analyze the following Reddit discussions about '{keyword}' and identify 3-5 concrete business ideas or opportunities.\n\n{context}\n\nFor each business idea, provide:\n1. A catchy title\n2. Detailed description of the opportunity\n3. Target audience\n4. Specific pain point it addresses\n5. Evidence from the Reddit discussions\n6. Market potential (High/Medium/Low)\n7. Related keywords\n\nReturn the response as a JSON array of business ideas.\"\"\"\n    \n    try:\n        response = client.messages.create(\n            model=\"claude-sonnet-4-5-20250929\",\n            max_tokens=4000,\n            messages=[{\n                \"role\": \"user\",\n                \"content\": prompt\n            }]\n        )\n        \n        # Parse the response\n        response_text = response.content[0].text\n        \n        # Try to extract JSON from the response\n        import re\n        json_match = re.search(r'\\[.*\\]', response_text, re.DOTALL)\n        if json_match:\n            business_ideas = json.loads(json_match.group())\n            return business_ideas\n        else:\n            print(\"Could not parse JSON response from Claude\")\n            return []\n            \n    except Exception as e:\n        print(f\"Error analyzing business ideas with AI: {e}\")\n        return []",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "el0azpq2bf7",
   "source": "def search_posts_in_subreddit(reddit: praw.Reddit, subreddit_name: str, keyword: str, \n                              limit: int = 25, time_filter: str = 'month') -> List[Dict[str, Any]]:\n    \"\"\"\n    Search for posts containing the keyword in a specific subreddit.\n    \n    Args:\n        reddit: Authenticated Reddit client instance\n        subreddit_name: Name of the subreddit to search\n        keyword: The keyword to search for in posts\n        limit: Maximum number of posts to return (default: 25)\n        time_filter: Time filter for top posts ('hour', 'day', 'week', 'month', 'year', 'all')\n    \n    Returns:\n        List of dictionaries containing post information:\n        - title: Post title\n        - score: Post score (upvotes - downvotes)\n        - num_comments: Number of comments\n        - url: URL to the post\n        - created_utc: Post creation timestamp\n        - selftext: Post content/body\n        - author: Post author username\n    \"\"\"\n    posts = []\n    \n    try:\n        subreddit = reddit.subreddit(subreddit_name)\n        \n        # Search posts containing the keyword\n        for post in subreddit.search(keyword, sort='top', time_filter=time_filter, limit=limit):\n            posts.append({\n                'title': post.title,\n                'score': post.score,\n                'num_comments': post.num_comments,\n                'url': post.url,\n                'permalink': f\"https://reddit.com{post.permalink}\",\n                'created_utc': datetime.fromtimestamp(post.created_utc).isoformat(),\n                'selftext': post.selftext[:500] if post.selftext else '',  # Limit text length\n                'author': str(post.author) if post.author else '[deleted]'\n            })\n    except Exception as e:\n        print(f\"Error searching posts in r/{subreddit_name}: {e}\")\n    \n    return sorted(posts, key=lambda x: x['score'], reverse=True)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "m7mycirp77",
   "source": "def initialize_reddit_client():\n    \"\"\"\n    Initialize Reddit API client using PRAW (Python Reddit API Wrapper).\n    \n    Requires environment variables:\n    - REDDIT_CLIENT_ID: Your Reddit app client ID\n    - REDDIT_CLIENT_SECRET: Your Reddit app client secret\n    - REDDIT_USER_AGENT: A unique identifier for your app\n    \n    Returns:\n        praw.Reddit: Authenticated Reddit client instance\n    \"\"\"\n    return praw.Reddit(\n        client_id=os.getenv('REDDIT_CLIENT_ID'),\n        client_secret=os.getenv('REDDIT_CLIENT_SECRET'),\n        user_agent=os.getenv('REDDIT_USER_AGENT', 'BusinessIdeaFinder/1.0')\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}